{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seminar 1\n",
    "\n",
    "Fixed vs Floating point, vector norms, and stability concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed point contains a 1-bit sign, $m$-bits integer, and $n$-bits fractional part:\n",
    "$$\n",
    "\\text{decimal} = \n",
    "(-1)^{\\text{sign}} \\times \n",
    "\\Big(\n",
    "\\sum_{i=0}^{m-1} \\text{integer}[i] \\cdot base^{m-1-i} + \n",
    "\\sum_{i=0}^{n-1} \\text{fractional}[i] \\cdot base^{-i-1}\n",
    "\\Big)\n",
    "$$\n",
    "\n",
    "- range $[-2^m + 2^{-n}, 2^m - 2^{-n}]$\n",
    "- resolution $2^{-n}$\n",
    "- total storage is $m + n + 1$ bits\n",
    "\n",
    "<img src=\"https://i.ibb.co/k0bKtqS/fixedpoint.png\" style=\"width:500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_fixed_point_to_decimal(x, m=8, n=8):\n",
    "    \"\"\"\n",
    "    x - binary string of size 1 + m + n\n",
    "    m - size of an integer part\n",
    "    n - sze of a fractional part\n",
    "    \"\"\"\n",
    "    sign_part, integer_part, fractional_part = x[0], x[1:m+1], x[m+1:m+n+1]\n",
    "    sign_value = (-1) ** int(sign_part)\n",
    "    integer_value = sum([\n",
    "        int(v) * 2 ** i\n",
    "        for i, v in enumerate(integer_part[::-1])\n",
    "    ])\n",
    "    fractional_value = sum([\n",
    "        int(v) * 2 ** -(i + 1)\n",
    "        for i, v in enumerate(fractional_part)\n",
    "    ])\n",
    "    return sign_value * (integer_value + fractional_value)\n",
    "\n",
    "m, n = 8, 8\n",
    "x = '00000010100100000'\n",
    "print(binary_fixed_point_to_decimal(x, m, n) == 5.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '11111111111111111' # Insert a string corresponding to a minimal possible value\n",
    "print(binary_fixed_point_to_decimal(x, m, n) == -(2 ** m - 2 ** (-n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '01111111111111111' # Insert a string corresponding to a maximal possible value\n",
    "print(binary_fixed_point_to_decimal(x, m, n) == 2 ** m - 2 ** (-n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '00000000000000001' # Insert a string corresponding to an absolute minimal but nonzero possible value\n",
    "print(binary_fixed_point_to_decimal(x, m, n) == 2 ** (-n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Floating point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Floating point contains a 1-bit sign, $m$-bits exponent, and $n$-bits mantissa part:\n",
    "\n",
    "$$\n",
    "\\text{decimal} = \n",
    "(-1)^{\\text{sign}} \\times \n",
    "base^{\\Big(\\sum_{i=0}^{m-1} \\text{exponent}[i] \\cdot base^{i} - (2^{m-1} - 1)\\Big)}\n",
    "\\times\n",
    "\\Big(1 + \\sum_{i=0}^{n-1} \\text{mantissa}[i] \\cdot base^{-i-1}\\Big)\n",
    "$$\n",
    "\n",
    "- exponent values that are all 0 and all 1 are reserved for special numbers: NaN, infinity, etc.\n",
    "- total storage is $m + n + 1$ bits\n",
    "\n",
    "<img src=\"https://i.ibb.co/MSk5Drs/floatingpoint.png\" style=\"width:700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half (float16) vs Single (float32) vs and Double (float32) Precision\n",
    "\n",
    "- float16 - 16 bit total: 1 for a sign, $m = 5$ for exponent and $n = 10$ for mantissa\n",
    "- float32 - 32 bits total: 1 for a sign, $m = 8$ for exponent and $n = 23$ for mantissa\n",
    "- float64 - 64 bits total: 1 for a sign, $m = 11$ for exponent and $n = 52$ for mantissa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_floating_point_to_decimal(x, m=8, n=23):\n",
    "    \"\"\"\n",
    "    x - binary string of size 1 + m + n\n",
    "    m - size of an exponent part\n",
    "    n - sze of a mantissa part\n",
    "    \"\"\"\n",
    "    sign_part, exponent_part, mantissa_part = x[0], x[1:m+1], x[m+1:n+m+1]\n",
    "    sign_value = (-1) ** int(sign_part)\n",
    "\n",
    "    mantissa_value = 1\n",
    "    for i, v in enumerate(mantissa_part):\n",
    "        mantissa_value += int(v) * (2 ** -(i + 1))\n",
    "\n",
    "    exponent_value = 0\n",
    "    for i, v in enumerate(exponent_part):\n",
    "        exponent_value += int(v) * 2 ** i\n",
    "    exponent_value -= (2 ** (m - 1) - 1)\n",
    "        \n",
    "    return sign_value * (2 ** exponent_value) * mantissa_value\n",
    "\n",
    "m, n = 8, 23\n",
    "x = '01000000101001000000000000000000'\n",
    "print(binary_floating_point_to_decimal(x, m, n) == 5.125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rounding Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that float representations are only approximations to real numbers, some errors may occur.\n",
    "\n",
    "For example, let's consider a simple summation algorithm, where $x_i$ are floating point numbers:\n",
    "\n",
    "$$\n",
    "f(x) = x_1 + x_2 + ... + x_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realize a na√Øve algorithm from the lecture (add one-by-one) and check out the occuring error.\n",
    "\n",
    "[!] Set $n$ as 1000 and all $x_i$ as 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0.0\n",
    "for _ in range(1000):\n",
    "    total += 0.1\n",
    "\n",
    "print(\"Expected result: 100.0\")\n",
    "print(f\"Actual result:\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realize a Kahan algorithm from the lecture and check out the occuring error.\n",
    "\n",
    "[!] Set $n$ as 1000 and all $x_i$ as 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "c = 0\n",
    "for i in range(1000):\n",
    "    y = 0.1 - c\n",
    "    t = s + y\n",
    "    c = (t - s) - y\n",
    "    s = t\n",
    "\n",
    "print(\"Expected result: 100.0\")\n",
    "print(f\"Actual result:\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: the value 0.1 cannot be represented precisely in binary so it becomes an approximation. When this approximation is added repeatedly, the small rounding errors accumulate, leading to a final result slightly less than 100.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectors and vector norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLA we typically work not with numbers, but with vectors that are simply arrays of numbers of size $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(f'Size of the x vector is {len(x)}')\n",
    "print(f'Type of the vector elements is {type(x[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this vector contains only integer values. Now convert them into float32 type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype(np.float32)\n",
    "print(f'Type of the vector elements is {type(x[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to measure smallness of a vector its **norm** $\\|x\\|$ is used.\n",
    "The most important class is $p$-norms:\n",
    "$$\n",
    "\\|x\\|_p = \\Big(\\sum_{i=1}^n |x_i|^p\\Big)^{1/p}\n",
    "$$\n",
    "Examples of $p$-norms:\n",
    "- Manhattan distance or $L_1$ norm - when $p=1$\n",
    "- Euclidean norm or $L_2$ norm - when $p=2$\n",
    "- Infinity norm, or Chebyshev norm - when $p=+\\infty$: $ \\|x\\|_{\\infty} = \\max_i | x_i|$\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute norms for the $x$ vector:\n",
    "\n",
    "Hint: use np.linalg.norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('L1 norm:', np.linalg.norm(x, 1))\n",
    "print('L2 norm:', np.linalg.norm(x, 2))\n",
    "print('Chebyshev norm:', np.linalg.norm(x, np.inf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A unit disk for a p-norm is a set of point such that $\\|x\\|_p = 1$.\n",
    "\n",
    "Visualize p-norm unit disk for the following p-norms: $p \\in (0.25, 0.75, 1.0, 2.0, 5.0, \\infty)$\n",
    "\n",
    "Hint: $y = \\pm (1 - |x|^p)^{1/p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def unit_disk(p):\n",
    "    x = np.linspace(-1, 1, 201)\n",
    "    y = (1 - np.abs(x) ** p) ** (1 / p)\n",
    "    x = np.hstack([x, x[1:][::-1], x[0]])\n",
    "    y = np.hstack([y, -y[1:][::-1], y[0]])\n",
    "    return x, y\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.axis('equal')\n",
    "for p in (0.25, 0.5, 1.0, 2.0, 5.0, np.inf):\n",
    "    x, y = unit_disk(p)\n",
    "    plt.plot(x, y, label=f'$p$={p}')\n",
    "plt.legend(loc=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have a vector $x$, function $f(x)$, and an algorithm $\\text{alg}(x)$ to approximate the function. Then the algorithm is called **forward stable**, if for some small $\\varepsilon$\n",
    "\n",
    "$$\n",
    "\\|\\text{alg}(x) - f(x)\\|  \\leq \\varepsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Task] Check the summation algorithms mentioned before (naive and Kahan) to be forward stable. \n",
    "\n",
    "Set each $x_i$ as 0.1 againg and $n$ as 100.\n",
    "$$\n",
    "f(x) = \\sum_{i=1}^{100} x_i, \\;\\;\n",
    "x_i = 0.1\n",
    "$$\n",
    "Record the error occuring in each step of summation: \n",
    "$$\n",
    "\\text{error}[i] = |0.1 \\cdot i - \\text{alg}(x)|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "\n",
    "# Naive\n",
    "total = 0.0\n",
    "error_naive = []\n",
    "for i in range(N):\n",
    "    total += 0.1\n",
    "    refer = (i + 1) / 10\n",
    "    error_naive.append(np.abs(refer - total))\n",
    "\n",
    "# Kahan\n",
    "s = 0\n",
    "c = 0\n",
    "error_kahan = []\n",
    "for i in range(N):\n",
    "    y = 0.1 - c\n",
    "    t = s + y\n",
    "    c = (t - s) - y\n",
    "    s = t\n",
    "    error_kahan.append(np.abs(c))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.title(r'Forward stability of summation algorithms $\\varepsilon(n)$')\n",
    "plt.plot(error_naive, label='Naive')\n",
    "plt.plot(error_kahan, label='Kahan')\n",
    "plt.ylabel(r'$\\varepsilon$', rotation=0)\n",
    "plt.xlabel(r'$n$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pupa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
